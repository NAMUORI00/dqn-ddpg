"""
ì¢…í•©ì ì¸ ì‹œê°í™” í†µí•©ì˜ìƒ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
ê²Œì„í”Œë ˆì´ + ì‹¤ì‹œê°„ ê·¸ë˜í”„ + ë¹„êµë¶„ì„ì„ ëª¨ë‘ í¬í•¨í•œ ì™„ì „í•œ ì‹œê°í™”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import numpy as np
import sys
import os
import gymnasium as gym
import cv2
import argparse
from pathlib import Path
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€ (scripts/video/specializedì—ì„œ ë£¨íŠ¸ë¡œ)
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from src.environments.comprehensive_visualization_wrapper import (
    ComprehensiveVisualizationWrapper, 
    create_side_by_side_comparison
)
from src.agents.dqn_agent import DQNAgent
from src.agents.ddpg_agent import DDPGAgent


def create_comprehensive_demo_video():
    """ì¢…í•© ì‹œê°í™” ë°ëª¨ ë¹„ë””ì˜¤ ìƒì„±"""
    print("=== ì¢…í•© ì‹œê°í™” í†µí•©ì˜ìƒ ìƒì„± ===")
    
    # ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ë£¨íŠ¸ë¡œ ë³€ê²½
    os.chdir(project_root)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = Path("videos/comprehensive_visualization")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # 1. DQN í™˜ê²½ ì„¤ì •
    dqn_env = gym.make('CartPole-v1', render_mode='rgb_array')
    dqn_wrapper = ComprehensiveVisualizationWrapper(
        dqn_env,
        algorithm_name="DQN",
        frame_width=600,
        frame_height=400,
        graph_height=300,
        stats_height=150
    )
    
    # 2. DDPG í™˜ê²½ ì„¤ì •  
    ddpg_env = gym.make('Pendulum-v1', render_mode='rgb_array')
    ddpg_wrapper = ComprehensiveVisualizationWrapper(
        ddpg_env,
        algorithm_name="DDPG",
        frame_width=600,
        frame_height=400,
        graph_height=300,
        stats_height=150
    )
    
    # ìƒí˜¸ ì°¸ì¡° ì„¤ì • (ë¹„êµìš©)
    dqn_wrapper.partner_wrapper = ddpg_wrapper
    ddpg_wrapper.partner_wrapper = dqn_wrapper
    
    # 3. ë¹„ë””ì˜¤ ë¼ì´í„° ì„¤ì •
    # ì²« í”„ë ˆì„ìœ¼ë¡œ í¬ê¸° í™•ì¸
    dqn_wrapper.reset()
    ddpg_wrapper.reset()
    
    combined_frame = create_side_by_side_comparison(dqn_wrapper, ddpg_wrapper)
    if combined_frame is None:
        print("ERROR: í”„ë ˆì„ ìƒì„± ì‹¤íŒ¨")
        return
    
    height, width = combined_frame.shape[:2]
    fps = 30
    
    # ë©”ì¸ ë¹„ë””ì˜¤ (ë‚˜ë€íˆ ë¹„êµ)
    main_output = output_dir / "comprehensive_dqn_vs_ddpg.mp4"
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    main_writer = cv2.VideoWriter(str(main_output), fourcc, fps, (width, height))
    
    # ê°œë³„ ë¹„ë””ì˜¤ë“¤ë„ ìƒì„±
    dqn_output = output_dir / "dqn_comprehensive.mp4"
    ddpg_output = output_dir / "ddpg_comprehensive.mp4"
    
    dqn_single_frame = dqn_wrapper.render()
    ddpg_single_frame = ddpg_wrapper.render()
    
    dqn_writer = cv2.VideoWriter(str(dqn_output), fourcc, fps, 
                                (dqn_single_frame.shape[1], dqn_single_frame.shape[0]))
    ddpg_writer = cv2.VideoWriter(str(ddpg_output), fourcc, fps,
                                 (ddpg_single_frame.shape[1], ddpg_single_frame.shape[0]))
    
    print(f"ë©”ì¸ í†µí•© ë¹„ë””ì˜¤: {main_output}")
    print(f"DQN ê°œë³„ ë¹„ë””ì˜¤: {dqn_output}")
    print(f"DDPG ê°œë³„ ë¹„ë””ì˜¤: {ddpg_output}")
    print(f"í”„ë ˆì„ í¬ê¸°: {width}x{height}")
    
    # 4. ì—í”¼ì†Œë“œ ì‹¤í–‰ ë° ë…¹í™”
    total_episodes = 25
    print(f"\n{total_episodes}ê°œ ì—í”¼ì†Œë“œ ì‹¤í–‰ ì‹œì‘...")
    
    for episode in range(total_episodes):
        print(f"\nì—í”¼ì†Œë“œ {episode + 1}/{total_episodes}")
        
        # í™˜ê²½ ë¦¬ì…‹
        dqn_wrapper.reset()
        ddpg_wrapper.reset()
        
        dqn_done = False
        ddpg_done = False
        step = 0
        max_steps = 500
        
        while step < max_steps and (not dqn_done or not ddpg_done):
            # DQN ìŠ¤í…
            if not dqn_done:
                dqn_action = dqn_wrapper.action_space.sample()
                _, dqn_reward, dqn_terminated, dqn_truncated, _ = dqn_wrapper.step(dqn_action)
                dqn_done = dqn_terminated or dqn_truncated
                
                # ì‹œë®¬ë ˆì´ì…˜ëœ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                if step % 5 == 0:
                    fake_q_value = np.random.randn() * 5 + episode * 2
                    fake_loss = np.exp(-episode * 0.05) * (0.1 + np.random.rand() * 0.1)
                    fake_exploration = max(0.01, 1.0 - episode * 0.04)
                    
                    dqn_wrapper.update_metrics(
                        q_value=fake_q_value,
                        loss=fake_loss,
                        exploration_rate=fake_exploration
                    )
            
            # DDPG ìŠ¤í…
            if not ddpg_done:
                ddpg_action = ddpg_wrapper.action_space.sample()
                _, ddpg_reward, ddpg_terminated, ddpg_truncated, _ = ddpg_wrapper.step(ddpg_action)
                ddpg_done = ddpg_terminated or ddpg_truncated
                
                # ì‹œë®¬ë ˆì´ì…˜ëœ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                if step % 5 == 0:
                    fake_q_value = -200 + episode * 8 + np.random.randn() * 15
                    fake_loss = np.exp(-episode * 0.03) * (0.05 + np.random.rand() * 0.08)
                    
                    ddpg_wrapper.update_metrics(
                        q_value=fake_q_value,
                        loss=fake_loss
                    )
            
            # í”„ë ˆì„ ë Œë”ë§ ë° ì €ì¥
            # 1. ë©”ì¸ í†µí•© ë¹„ë””ì˜¤
            combined_frame = create_side_by_side_comparison(dqn_wrapper, ddpg_wrapper)
            if combined_frame is not None:
                main_writer.write(cv2.cvtColor(combined_frame, cv2.COLOR_RGB2BGR))
            
            # 2. ê°œë³„ ë¹„ë””ì˜¤ë“¤
            dqn_frame = dqn_wrapper.render()
            ddpg_frame = ddpg_wrapper.render()
            
            if dqn_frame is not None:
                dqn_writer.write(cv2.cvtColor(dqn_frame, cv2.COLOR_RGB2BGR))
            
            if ddpg_frame is not None:
                ddpg_writer.write(cv2.cvtColor(ddpg_frame, cv2.COLOR_RGB2BGR))
            
            step += 1
        
        # ì—í”¼ì†Œë“œ ê²°ê³¼ ì¶œë ¥
        print(f"  DQN: {dqn_wrapper.current_step} ìŠ¤í…, ë³´ìƒ {dqn_wrapper.total_reward:.1f}")
        print(f"  DDPG: {ddpg_wrapper.current_step} ìŠ¤í…, ë³´ìƒ {ddpg_wrapper.total_reward:.1f}")
    
    # 5. ì •ë¦¬
    main_writer.release()
    dqn_writer.release() 
    ddpg_writer.release()
    dqn_wrapper.close()
    ddpg_wrapper.close()
    
    print(f"\nâœ… ì¢…í•© ì‹œê°í™” ì˜ìƒ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {output_dir}")
    print(f"ğŸ¬ ë©”ì¸ í†µí•© ì˜ìƒ: comprehensive_dqn_vs_ddpg.mp4")
    print(f"ğŸ¬ DQN ê°œë³„ ì˜ìƒ: dqn_comprehensive.mp4")
    print(f"ğŸ¬ DDPG ê°œë³„ ì˜ìƒ: ddpg_comprehensive.mp4")
    
    # ìµœì¢… ìŠ¤í¬ë¦°ìƒ·ë„ ì €ì¥
    save_final_screenshots(output_dir)


def save_final_screenshots(output_dir: Path):
    """ìµœì¢… ìŠ¤í¬ë¦°ìƒ· ì €ì¥"""
    print("\nğŸ“¸ ìµœì¢… ìŠ¤í¬ë¦°ìƒ· ìƒì„± ì¤‘...")
    
    # ìƒˆë¡œìš´ í™˜ê²½ìœ¼ë¡œ ìŠ¤í¬ë¦°ìƒ· ìƒì„±
    dqn_env = gym.make('CartPole-v1', render_mode='rgb_array')
    dqn_wrapper = ComprehensiveVisualizationWrapper(dqn_env, algorithm_name="DQN")
    
    ddpg_env = gym.make('Pendulum-v1', render_mode='rgb_array')
    ddpg_wrapper = ComprehensiveVisualizationWrapper(ddpg_env, algorithm_name="DDPG")
    
    # ëª‡ ì—í”¼ì†Œë“œ ì‹¤í–‰í•˜ì—¬ ë°ì´í„° ì¶•ì 
    for episode in range(10):
        for wrapper in [dqn_wrapper, ddpg_wrapper]:
            wrapper.reset()
            done = False
            step = 0
            
            while not done and step < 200:
                action = wrapper.action_space.sample()
                _, _, terminated, truncated, _ = wrapper.step(action)
                done = terminated or truncated
                step += 1
                
                # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                if step % 10 == 0:
                    if wrapper.algorithm_name == "DQN":
                        wrapper.update_metrics(
                            q_value=np.random.randn() * 5 + episode,
                            loss=np.exp(-episode * 0.1) * 0.1
                        )
                    else:
                        wrapper.update_metrics(
                            q_value=-150 + episode * 10 + np.random.randn() * 20,
                            loss=np.exp(-episode * 0.05) * 0.05
                        )
    
    # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
    screenshots_dir = output_dir / "screenshots"
    screenshots_dir.mkdir(exist_ok=True)
    
    # ê°œë³„ ìŠ¤í¬ë¦°ìƒ·
    dqn_frame = dqn_wrapper.render()
    ddpg_frame = ddpg_wrapper.render()
    
    if dqn_frame is not None:
        cv2.imwrite(str(screenshots_dir / "dqn_comprehensive_final.png"),
                   cv2.cvtColor(dqn_frame, cv2.COLOR_RGB2BGR))
    
    if ddpg_frame is not None:
        cv2.imwrite(str(screenshots_dir / "ddpg_comprehensive_final.png"),
                   cv2.cvtColor(ddpg_frame, cv2.COLOR_RGB2BGR))
    
    # í†µí•© ë¹„êµ ìŠ¤í¬ë¦°ìƒ·
    combined_frame = create_side_by_side_comparison(dqn_wrapper, ddpg_wrapper)
    if combined_frame is not None:
        cv2.imwrite(str(screenshots_dir / "comprehensive_comparison_final.png"),
                   cv2.cvtColor(combined_frame, cv2.COLOR_RGB2BGR))
    
    dqn_wrapper.close()
    ddpg_wrapper.close()
    
    print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ì™„ë£Œ: {screenshots_dir}")


def create_with_real_agents():
    """ì‹¤ì œ ì—ì´ì „íŠ¸ì™€ í•¨ê»˜ ì¢…í•© ì‹œê°í™” ìƒì„±"""
    print("\n=== ì‹¤ì œ ì—ì´ì „íŠ¸ì™€ í•¨ê»˜ ì¢…í•© ì‹œê°í™” ===")
    
    output_dir = Path("videos/comprehensive_visualization")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # DQN í™˜ê²½ ë° ì—ì´ì „íŠ¸
    dqn_env = gym.make('CartPole-v1', render_mode='rgb_array')
    dqn_wrapper = ComprehensiveVisualizationWrapper(dqn_env, algorithm_name="DQN")
    
    dqn_agent = DQNAgent(
        state_dim=dqn_env.observation_space.shape[0],
        action_dim=dqn_env.action_space.n,
        learning_rate=0.001,
        gamma=0.99,
        epsilon=1.0,
        epsilon_decay=0.995,
        epsilon_min=0.01
    )
    
    # DDPG í™˜ê²½ ë° ì—ì´ì „íŠ¸  
    ddpg_env = gym.make('Pendulum-v1', render_mode='rgb_array')
    ddpg_wrapper = ComprehensiveVisualizationWrapper(ddpg_env, algorithm_name="DDPG")
    
    ddpg_agent = DDPGAgent(
        state_dim=ddpg_env.observation_space.shape[0],
        action_dim=ddpg_env.action_space.shape[0],
        max_action=float(ddpg_env.action_space.high[0]),
        learning_rate=0.001,
        gamma=0.99,
        tau=0.005
    )
    
    # ë¹„ë””ì˜¤ ì„¤ì •
    output_path = output_dir / "comprehensive_with_real_agents.mp4"
    
    combined_frame = create_side_by_side_comparison(dqn_wrapper, ddpg_wrapper)
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    video_writer = cv2.VideoWriter(str(output_path), fourcc, 30.0, 
                                  (combined_frame.shape[1], combined_frame.shape[0]))
    
    print(f"ì‹¤ì œ ì—ì´ì „íŠ¸ ë¹„ë””ì˜¤: {output_path}")
    
    # í•™ìŠµ ë° ë…¹í™”
    for episode in range(15):
        print(f"\nì—í”¼ì†Œë“œ {episode + 1}/15")
        
        # DQN ì—í”¼ì†Œë“œ
        dqn_state, _ = dqn_wrapper.reset()
        dqn_done = False
        
        while not dqn_done:
            dqn_action = dqn_agent.act(dqn_state)
            dqn_next_state, dqn_reward, dqn_terminated, dqn_truncated, _ = dqn_wrapper.step(dqn_action)
            dqn_done = dqn_terminated or dqn_truncated
            
            # í•™ìŠµ
            dqn_agent.remember(dqn_state, dqn_action, dqn_reward, dqn_next_state, dqn_done)
            if len(dqn_agent.memory) > 32:
                loss = dqn_agent.replay()
                q_values = dqn_agent.q_network(dqn_agent._to_tensor(dqn_state))
                max_q = q_values.max().item()
                
                dqn_wrapper.update_metrics(
                    q_value=max_q,
                    loss=loss,
                    exploration_rate=dqn_agent.epsilon
                )
            
            dqn_state = dqn_next_state
        
        # DDPG ì—í”¼ì†Œë“œ
        ddpg_state, _ = ddpg_wrapper.reset()
        ddpg_done = False
        step = 0
        
        while not ddpg_done and step < 200:
            ddpg_action = ddpg_agent.act(ddpg_state)
            ddpg_next_state, ddpg_reward, ddpg_terminated, ddpg_truncated, _ = ddpg_wrapper.step(ddpg_action)
            ddpg_done = ddpg_terminated or ddpg_truncated
            
            # í•™ìŠµ
            ddpg_agent.remember(ddpg_state, ddpg_action, ddpg_reward, ddpg_next_state, ddpg_done)
            if len(ddpg_agent.replay_buffer) > 100:
                actor_loss, critic_loss = ddpg_agent.train()
                q_value = ddpg_agent.critic(ddpg_agent._to_tensor(ddpg_state), 
                                          ddpg_agent._to_tensor(ddpg_action)).item()
                
                ddpg_wrapper.update_metrics(
                    q_value=q_value,
                    loss=critic_loss
                )
            
            ddpg_state = ddpg_next_state
            step += 1
        
        # í”„ë ˆì„ ì €ì¥ (ë§¤ ì—í”¼ì†Œë“œë§ˆë‹¤ ëª‡ í”„ë ˆì„)
        for _ in range(30):  # 1ì´ˆë¶„ì˜ í”„ë ˆì„
            combined_frame = create_side_by_side_comparison(dqn_wrapper, ddpg_wrapper)
            if combined_frame is not None:
                video_writer.write(cv2.cvtColor(combined_frame, cv2.COLOR_RGB2BGR))
        
        # íƒ€ê²Ÿ ë„¤íŠ¸ì›Œí¬ ì—…ë°ì´íŠ¸
        if episode % 10 == 0:
            dqn_agent.update_target_network()
        
        print(f"  DQN: {dqn_wrapper.total_reward:.1f}, DDPG: {ddpg_wrapper.total_reward:.1f}")
    
    video_writer.release()
    dqn_wrapper.close()
    ddpg_wrapper.close()
    
    print(f"\nâœ… ì‹¤ì œ ì—ì´ì „íŠ¸ ì¢…í•© ì‹œê°í™” ì™„ë£Œ: {output_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ì¢…í•© ì‹œê°í™” í†µí•©ì˜ìƒ ìƒì„±")
    parser.add_argument('--mode', type=str, default='demo',
                       choices=['demo', 'real_agents', 'both'],
                       help='ìƒì„± ëª¨ë“œ ì„ íƒ')
    
    args = parser.parse_args()
    
    if args.mode == 'demo':
        create_comprehensive_demo_video()
    elif args.mode == 'real_agents':
        create_with_real_agents()
    elif args.mode == 'both':
        create_comprehensive_demo_video()
        create_with_real_agents()
    
    print(f"\nğŸ‰ ëª¨ë“  ì¢…í•© ì‹œê°í™” ì˜ìƒ ìƒì„± ì™„ë£Œ!")
    print(f"ğŸ“ videos/comprehensive_visualization/ í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")