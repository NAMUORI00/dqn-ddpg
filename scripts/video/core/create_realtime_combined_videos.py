"""
ì‹¤ì‹œê°„ í•™ìŠµ ê·¸ë˜í”„ì™€ ê²Œì„í”Œë ˆì´ë¥¼ ê²°í•©í•œ í†µí•© ë¹„ë””ì˜¤ ìƒì„±

CartPoleê³¼ Pendulum í™˜ê²½ì—ì„œ DQNê³¼ DDPGì˜ í•™ìŠµ ê³¼ì •ê³¼
ì‹¤ì œ ê²Œì„í”Œë ˆì´ë¥¼ í•˜ë‚˜ì˜ í™”ë©´ì— ë™ì‹œì— ë³´ì—¬ì£¼ëŠ” ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
import sys
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import cv2
from pathlib import Path
import json
import argparse
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import glob

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€ (scripts/video/coreì—ì„œ ë£¨íŠ¸ë¡œ)
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))


class RealtimeCombinedVideoGenerator:
    """ì‹¤ì‹œê°„ í•™ìŠµ ê·¸ë˜í”„ì™€ ê²Œì„í”Œë ˆì´ë¥¼ ê²°í•©í•œ ë¹„ë””ì˜¤ ìƒì„±ê¸°"""
    
    def __init__(self, output_dir: str = "output/videos/combined"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ìƒ‰ìƒ ì„¤ì •
        self.colors = {
            'dqn': '#3498db',  # íŒŒë€ìƒ‰
            'ddpg': '#e74c3c',  # ë¹¨ê°„ìƒ‰
            'background': '#2c3e50',
            'grid': '#34495e',
            'text': '#ecf0f1'
        }
        
        # ë¹„ë””ì˜¤ ì„¤ì •
        self.fps = 30
        self.resolution = (1920, 1080)
        
    def load_training_data(self, env_type: str) -> Tuple[Dict, Dict]:
        """í™˜ê²½ë³„ í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
        # ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ë£¨íŠ¸ë¡œ ë³€ê²½
        os.chdir(project_root)
        
        if env_type == "cartpole":
            # CartPole ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
            dqn_path = "results/dqn_results.json"
            
            if os.path.exists(dqn_path):
                with open(dqn_path, 'r') as f:
                    dqn_data = json.load(f)
            else:
                dqn_data = self._create_sample_data('dqn', 'cartpole')
                
            # DDPGëŠ” CartPoleì—ì„œ í•­ìƒ ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš© (JSON íŒŒì¼ ì†ìƒ)
            ddpg_data = self._create_sample_data('ddpg', 'cartpole')
                
        else:  # pendulum
            # Pendulum ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
            comparison_path = "results/balanced_comparison/quick_demo_viz_20250615_174231.json"
            
            # ì˜¬ë°”ë¥¸ ë°ì´í„° ë¡œë“œ ë˜ëŠ” ìƒ˜í”Œ ë°ì´í„° ìƒì„±
            try:
                if os.path.exists(comparison_path):
                    with open(comparison_path, 'r') as f:
                        data = json.load(f)
                        # 300 ì—í”¼ì†Œë“œë¡œ ë§ì¶¤
                        dqn_rewards = data['dqn']['rewards'][:300] if len(data['dqn']['rewards']) >= 300 else data['dqn']['rewards']
                        ddpg_rewards = data['ddpg']['rewards'][:300] if len(data['ddpg']['rewards']) >= 300 else data['ddpg']['rewards']
                        
                        dqn_data = {
                            'metrics': {
                                'episode_rewards': dqn_rewards
                            }
                        }
                        ddpg_data = {
                            'metrics': {
                                'episode_rewards': ddpg_rewards
                            }
                        }
                else:
                    raise FileNotFoundError("Pendulum data not found")
            except:
                print("[INFO] Pendulum íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                dqn_data = self._create_sample_data('dqn', 'pendulum')
                ddpg_data = self._create_sample_data('ddpg', 'pendulum')
                
        return dqn_data, ddpg_data
    
    def _create_sample_data(self, algo: str, env: str) -> Dict:
        """ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
        np.random.seed(42)
        # ìµœì¢… ë³´ê³ ì„œì˜ ì‹¤í—˜ ì¡°ê±´ì— ë§ì¶¤
        episodes = 500 if env == 'cartpole' else 300
        
        if env == 'cartpole':
            if algo == 'dqn':
                # DQNì´ CartPoleì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥
                rewards = []
                for i in range(episodes):
                    base = min(500, 50 + i * 0.9)
                    noise = np.random.normal(0, 20)
                    rewards.append(max(0, base + noise))
            else:  # ddpg
                # DDPGê°€ CartPoleì—ì„œ ì €ì¡°í•œ ì„±ëŠ¥
                rewards = []
                for i in range(episodes):
                    base = min(100, 20 + i * 0.15)
                    noise = np.random.normal(0, 10)
                    rewards.append(max(0, base + noise))
        else:  # pendulum
            if algo == 'dqn':
                # DQNì´ Pendulumì—ì„œ ì €ì¡°í•œ ì„±ëŠ¥
                rewards = []
                for i in range(episodes):
                    base = max(-1600, -1600 + i * 2)
                    noise = np.random.normal(0, 100)
                    rewards.append(base + noise)
            else:  # ddpg
                # DDPGê°€ Pendulumì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥
                rewards = []
                for i in range(episodes):
                    base = max(-200, -1600 + i * 5)
                    noise = np.random.normal(0, 50)
                    rewards.append(base + noise)
                    
        return {
            'metrics': {
                'episode_rewards': rewards
            }
        }
    
    def load_gameplay_videos(self, env_type: str) -> Dict[str, List[str]]:
        """ê²Œì„í”Œë ˆì´ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë¡œë“œ"""
        video_paths = {
            'dqn': {'success': [], 'failure': []},
            'ddpg': {'success': [], 'failure': []}
        }
        
        # ë¹„ë””ì˜¤ ë””ë ‰í† ë¦¬ íƒìƒ‰
        base_dirs = ["videos/dqn", "videos/ddpg", "videos/success_failure", "output/videos/environment_success_failure"]
        
        for base_dir in base_dirs:
            if not os.path.exists(base_dir):
                continue
                
            # í™˜ê²½ë³„ ë¹„ë””ì˜¤ ì°¾ê¸°
            if env_type == "cartpole":
                # ì„±ê³µ ë¹„ë””ì˜¤
                patterns = ["*cartpole*success*.mp4", "*CartPole*success*.mp4", "*cartpole_dqn_success*.mp4"]
                for pattern in patterns:
                    files = glob.glob(os.path.join(base_dir, pattern))
                    for f in files:
                        if 'dqn' in f.lower() and f not in video_paths['dqn']['success']:
                            video_paths['dqn']['success'].append(f)
                        elif 'ddpg' in f.lower() and f not in video_paths['ddpg']['success']:
                            video_paths['ddpg']['success'].append(f)
                            
                # ì‹¤íŒ¨ ë¹„ë””ì˜¤
                patterns = ["*cartpole*failure*.mp4", "*CartPole*failure*.mp4", "*cartpole_ddpg_failure*.mp4"]
                for pattern in patterns:
                    files = glob.glob(os.path.join(base_dir, pattern))
                    for f in files:
                        if 'dqn' in f.lower() and f not in video_paths['dqn']['failure']:
                            video_paths['dqn']['failure'].append(f)
                        elif 'ddpg' in f.lower() and f not in video_paths['ddpg']['failure']:
                            video_paths['ddpg']['failure'].append(f)
                            
            else:  # pendulum
                # ì„±ê³µ ë¹„ë””ì˜¤
                patterns = ["*pendulum*success*.mp4", "*Pendulum*success*.mp4", "*pendulum_ddpg_success*.mp4"]
                for pattern in patterns:
                    files = glob.glob(os.path.join(base_dir, pattern))
                    for f in files:
                        if 'dqn' in f.lower() and f not in video_paths['dqn']['success']:
                            video_paths['dqn']['success'].append(f)
                        elif 'ddpg' in f.lower() and f not in video_paths['ddpg']['success']:
                            video_paths['ddpg']['success'].append(f)
                            
                # ì‹¤íŒ¨ ë¹„ë””ì˜¤
                patterns = ["*pendulum*failure*.mp4", "*Pendulum*failure*.mp4", "*pendulum_dqn_failure*.mp4"]
                for pattern in patterns:
                    files = glob.glob(os.path.join(base_dir, pattern))
                    for f in files:
                        if 'dqn' in f.lower() and f not in video_paths['dqn']['failure']:
                            video_paths['dqn']['failure'].append(f)
                        elif 'ddpg' in f.lower() and f not in video_paths['ddpg']['failure']:
                            video_paths['ddpg']['failure'].append(f)
        
        # ë””ë²„ê¹…: ì°¾ì€ ë¹„ë””ì˜¤ ì¶œë ¥
        print("\n[DEBUG] Found videos:")
        for algo in ['dqn', 'ddpg']:
            for status in ['success', 'failure']:
                if video_paths[algo][status]:
                    print(f"  {algo.upper()} {status}: {len(video_paths[algo][status])} files")
                    for path in video_paths[algo][status][:2]:  # ì²˜ìŒ 2ê°œë§Œ ì¶œë ¥
                        print(f"    - {path}")
        
        return video_paths
    
    def create_combined_video(self, env_type: str, duration: int = 60):
        """í™˜ê²½ë³„ í†µí•© ë¹„ë””ì˜¤ ìƒì„±"""
        print(f"\n{'='*60}")
        print(f"Creating combined video for {env_type.upper()} environment")
        print(f"{'='*60}")
        
        # ë°ì´í„° ë¡œë“œ
        dqn_data, ddpg_data = self.load_training_data(env_type)
        gameplay_videos = self.load_gameplay_videos(env_type)
        
        # matplotlib ì„¤ì •
        plt.style.use('dark_background')
        fig = plt.figure(figsize=(16, 9), facecolor=self.colors['background'])
        
        # 2x2 ë ˆì´ì•„ì›ƒ ìƒì„±
        gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3, 
                             left=0.05, right=0.95, top=0.93, bottom=0.05)
        
        # ì„œë¸Œí”Œë¡¯ ìƒì„±
        ax_dqn_graph = fig.add_subplot(gs[0, 0])
        ax_ddpg_graph = fig.add_subplot(gs[0, 1])
        ax_dqn_game = fig.add_subplot(gs[1, 0])
        ax_ddpg_game = fig.add_subplot(gs[1, 1])
        
        # ì œëª© ì„¤ì •
        env_title = "CartPole-v1" if env_type == "cartpole" else "Pendulum-v1"
        fig.suptitle(f"{env_title} Environment: DQN vs DDPG Real-time Comparison", 
                    fontsize=20, color=self.colors['text'])
        
        # ë¹„ë””ì˜¤ í”„ë ˆì„ ì¤€ë¹„
        dqn_rewards = dqn_data['metrics']['episode_rewards']
        ddpg_rewards = ddpg_data['metrics']['episode_rewards']
        
        # í™˜ê²½ë³„ ìµœëŒ€ ì—í”¼ì†Œë“œ ìˆ˜ ì„¤ì • (ìµœì¢… ë³´ê³ ì„œ ê¸°ì¤€)
        target_episodes = 500 if env_type == "cartpole" else 300
        max_episodes = min(len(dqn_rewards), len(ddpg_rewards), target_episodes)
        
        total_frames = self.fps * duration
        episodes_per_frame = max_episodes / total_frames
        
        # ë¹„ë””ì˜¤ ë¼ì´í„° ì„¤ì •
        output_path = self.output_dir / f"{env_type}_realtime_comparison.mp4"
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(str(output_path), fourcc, self.fps, self.resolution)
        
        print(f"Generating {total_frames} frames at {self.fps} fps...")
        
        # ê²Œì„í”Œë ˆì´ ë¹„ë””ì˜¤ ìº¡ì²˜ ì¤€ë¹„
        gameplay_caps = self._prepare_gameplay_captures(gameplay_videos)
        
        for frame in range(total_frames):
            current_episode = int(frame * episodes_per_frame)
            
            # í•™ìŠµ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸
            self._update_learning_graphs(ax_dqn_graph, ax_ddpg_graph, 
                                       dqn_rewards, ddpg_rewards, 
                                       current_episode, env_type)
            
            # ê²Œì„í”Œë ˆì´ í”„ë ˆì„ ì—…ë°ì´íŠ¸
            progress = frame / total_frames
            self._update_gameplay_frames(ax_dqn_game, ax_ddpg_game, 
                                       gameplay_caps, progress, env_type)
            
            # matplotlib figureë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            fig.canvas.draw()
            # ìƒˆë¡œìš´ matplotlib ë²„ì „ í˜¸í™˜ì„±
            try:
                img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
            except AttributeError:
                # ìƒˆ ë²„ì „ì˜ matplotlib
                img = np.array(fig.canvas.buffer_rgba())
                img = img[:, :, :3]  # RGBAì—ì„œ RGBë¡œ ë³€í™˜
            
            if len(img.shape) == 1:
                img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))
            
            # BGRë¡œ ë³€í™˜í•˜ê³  í•´ìƒë„ ì¡°ì •
            img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
            img_resized = cv2.resize(img_bgr, self.resolution)
            
            # í”„ë ˆì„ ì“°ê¸°
            out.write(img_resized)
            
            # ì§„í–‰ë¥  í‘œì‹œ
            if frame % 30 == 0:
                print(f"Progress: {frame/total_frames*100:.1f}%")
        
        # ì •ë¦¬
        out.release()
        plt.close(fig)
        
        # ê²Œì„í”Œë ˆì´ ìº¡ì²˜ í•´ì œ
        for cap_dict in gameplay_caps.values():
            for cap in cap_dict.values():
                if cap is not None:
                    cap.release()
        
        print(f"\nVideo saved: {output_path}")
        print(f"File size: {output_path.stat().st_size / (1024*1024):.1f} MB")
        
        return str(output_path)
    
    def _update_learning_graphs(self, ax_dqn, ax_ddpg, dqn_rewards, ddpg_rewards, 
                               current_episode, env_type):
        """í•™ìŠµ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸"""
        # DQN ê·¸ë˜í”„
        ax_dqn.clear()
        if current_episode > 0:
            episodes = range(current_episode)
            ax_dqn.plot(episodes, dqn_rewards[:current_episode], 
                       color=self.colors['dqn'], linewidth=2, alpha=0.8)
            
            # ì´ë™í‰ê· 
            if current_episode > 20:
                window = 20
                ma = np.convolve(dqn_rewards[:current_episode], 
                               np.ones(window)/window, mode='valid')
                ax_dqn.plot(range(window-1, current_episode), ma, 
                          color=self.colors['dqn'], linewidth=3)
        
        ax_dqn.set_title('DQN Learning Progress', color=self.colors['text'], fontsize=14)
        ax_dqn.set_xlabel('Episode', color=self.colors['text'])
        ax_dqn.set_ylabel('Reward', color=self.colors['text'])
        ax_dqn.grid(True, alpha=0.3, color=self.colors['grid'])
        ax_dqn.set_facecolor(self.colors['background'])
        
        # DDPG ê·¸ë˜í”„
        ax_ddpg.clear()
        if current_episode > 0:
            episodes = range(current_episode)
            ax_ddpg.plot(episodes, ddpg_rewards[:current_episode], 
                        color=self.colors['ddpg'], linewidth=2, alpha=0.8)
            
            # ì´ë™í‰ê· 
            if current_episode > 20:
                window = 20
                ma = np.convolve(ddpg_rewards[:current_episode], 
                               np.ones(window)/window, mode='valid')
                ax_ddpg.plot(range(window-1, current_episode), ma, 
                           color=self.colors['ddpg'], linewidth=3)
        
        ax_ddpg.set_title('DDPG Learning Progress', color=self.colors['text'], fontsize=14)
        ax_ddpg.set_xlabel('Episode', color=self.colors['text'])
        ax_ddpg.set_ylabel('Reward', color=self.colors['text'])
        ax_ddpg.grid(True, alpha=0.3, color=self.colors['grid'])
        ax_ddpg.set_facecolor(self.colors['background'])
        
        # Yì¶• ë²”ìœ„ ì„¤ì •
        if env_type == "cartpole":
            ax_dqn.set_ylim(0, 550)
            ax_ddpg.set_ylim(0, 550)
        else:  # pendulum
            ax_dqn.set_ylim(-1800, 0)
            ax_ddpg.set_ylim(-1800, 0)
    
    def _prepare_gameplay_captures(self, gameplay_videos: Dict) -> Dict:
        """ê²Œì„í”Œë ˆì´ ë¹„ë””ì˜¤ ìº¡ì²˜ ì¤€ë¹„"""
        captures = {
            'dqn': {'success': None, 'failure': None},
            'ddpg': {'success': None, 'failure': None}
        }
        
        for algo in ['dqn', 'ddpg']:
            if gameplay_videos[algo]['success']:
                cap = cv2.VideoCapture(gameplay_videos[algo]['success'][0])
                if cap.isOpened():
                    captures[algo]['success'] = cap
                    
            if gameplay_videos[algo]['failure']:
                cap = cv2.VideoCapture(gameplay_videos[algo]['failure'][0])
                if cap.isOpened():
                    captures[algo]['failure'] = cap
                    
        return captures
    
    def _update_gameplay_frames(self, ax_dqn, ax_ddpg, gameplay_caps, progress, env_type):
        """ê²Œì„í”Œë ˆì´ í”„ë ˆì„ ì—…ë°ì´íŠ¸"""
        # ì§„í–‰ë„ì— ë”°ë¼ ì„±ê³µ/ì‹¤íŒ¨ ë¹„ë””ì˜¤ ì„ íƒ
        video_type = 'failure' if progress < 0.5 else 'success'
        
        # ëŒ€ì²´ ë¹„ë””ì˜¤ íƒ€ì… (ì—†ì„ ê²½ìš°)
        alt_video_type = 'success' if video_type == 'failure' else 'failure'
        
        # DQN ê²Œì„í”Œë ˆì´
        ax_dqn.clear()
        ax_dqn.axis('off')
        
        # ì›í•˜ëŠ” íƒ€ì…ì´ ì—†ìœ¼ë©´ ëŒ€ì²´ íƒ€ì… ì‚¬ìš©
        cap_to_use = gameplay_caps['dqn'][video_type] or gameplay_caps['dqn'][alt_video_type]
        
        if cap_to_use is not None:
            ret, frame = cap_to_use.read()
            if ret:
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                ax_dqn.imshow(frame_rgb)
            else:
                # ë¹„ë””ì˜¤ ëë‚˜ë©´ ì²˜ìŒìœ¼ë¡œ
                cap_to_use.set(cv2.CAP_PROP_POS_FRAMES, 0)
                ret, frame = cap_to_use.read()
                if ret:
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    ax_dqn.imshow(frame_rgb)
        else:
            # í”Œë ˆì´ìŠ¤í™€ë”
            ax_dqn.text(0.5, 0.5, f'DQN Gameplay\n({video_type.upper()})', 
                       ha='center', va='center', transform=ax_dqn.transAxes,
                       fontsize=16, color=self.colors['dqn'])
        
        # í™˜ê²½ë³„ ì—í”¼ì†Œë“œ ìˆ˜ ì„¤ì •
        max_episodes = 500 if env_type == "cartpole" else 300
        ax_dqn.set_title(f'DQN Gameplay - Episode {int(progress * max_episodes)}', 
                        color=self.colors['text'], fontsize=12)
        
        # DDPG ê²Œì„í”Œë ˆì´
        ax_ddpg.clear()
        ax_ddpg.axis('off')
        
        # ì›í•˜ëŠ” íƒ€ì…ì´ ì—†ìœ¼ë©´ ëŒ€ì²´ íƒ€ì… ì‚¬ìš©
        cap_to_use = gameplay_caps['ddpg'][video_type] or gameplay_caps['ddpg'][alt_video_type]
        
        if cap_to_use is not None:
            ret, frame = cap_to_use.read()
            if ret:
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                ax_ddpg.imshow(frame_rgb)
            else:
                # ë¹„ë””ì˜¤ ëë‚˜ë©´ ì²˜ìŒìœ¼ë¡œ
                cap_to_use.set(cv2.CAP_PROP_POS_FRAMES, 0)
                ret, frame = cap_to_use.read()
                if ret:
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    ax_ddpg.imshow(frame_rgb)
        else:
            # í”Œë ˆì´ìŠ¤í™€ë”
            ax_ddpg.text(0.5, 0.5, f'DDPG Gameplay\n({video_type.upper()})', 
                        ha='center', va='center', transform=ax_ddpg.transAxes,
                        fontsize=16, color=self.colors['ddpg'])
        
        ax_ddpg.set_title(f'DDPG Gameplay - Episode {int(progress * max_episodes)}', 
                         color=self.colors['text'], fontsize=12)


def main():
    parser = argparse.ArgumentParser(description="ì‹¤ì‹œê°„ í•™ìŠµ ê·¸ë˜í”„ì™€ ê²Œì„í”Œë ˆì´ í†µí•© ë¹„ë””ì˜¤ ìƒì„±")
    
    parser.add_argument("--cartpole", action="store_true", 
                       help="CartPole í™˜ê²½ ë¹„ë””ì˜¤ ìƒì„±")
    parser.add_argument("--pendulum", action="store_true",
                       help="Pendulum í™˜ê²½ ë¹„ë””ì˜¤ ìƒì„±")
    parser.add_argument("--all", action="store_true",
                       help="ëª¨ë“  í™˜ê²½ ë¹„ë””ì˜¤ ìƒì„±")
    parser.add_argument("--duration", type=int, default=60,
                       help="ë¹„ë””ì˜¤ ê¸¸ì´ (ì´ˆ)")
    parser.add_argument("--output-dir", type=str, default="videos/combined",
                       help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    
    args = parser.parse_args()
    
    # ê¸°ë³¸ê°’: ëª¨ë“  í™˜ê²½
    if not args.cartpole and not args.pendulum and not args.all:
        args.all = True
    
    generator = RealtimeCombinedVideoGenerator(args.output_dir)
    
    print("="*60)
    print("ğŸ¬ Real-time Learning + Gameplay Combined Video Generator")
    print("="*60)
    
    videos_created = []
    
    if args.all or args.cartpole:
        video_path = generator.create_combined_video("cartpole", args.duration)
        videos_created.append(video_path)
    
    if args.all or args.pendulum:
        video_path = generator.create_combined_video("pendulum", args.duration)
        videos_created.append(video_path)
    
    print("\n" + "="*60)
    print("âœ… Video generation completed!")
    print("="*60)
    print("\nCreated videos:")
    for video in videos_created:
        print(f"  - {video}")


if __name__ == "__main__":
    main()