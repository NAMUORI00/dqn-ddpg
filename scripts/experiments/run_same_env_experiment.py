"""
ë™ì¼ í™˜ê²½ DQN vs DDPG ì‹¤í—˜ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ì•ì„  ì‹¤í—˜ì—ì„œ DQNì´ ë§¤ìš° ì¢‹ì€ ì„±ëŠ¥(498.95)ì„, DDPGëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì€ ì„±ëŠ¥(37.80)ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.
ê²°ê³¼ë¥¼ ì €ì¥í•˜ê³  ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.
"""

import os
import sys
import numpy as np
import json
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€ (scripts/experimentsì—ì„œ ë£¨íŠ¸ë¡œ)
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

def create_experiment_summary():
    """ì‹¤í—˜ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
    
    # ì•ì„  ì‹¤í—˜ì—ì„œ ì–»ì€ ì£¼ìš” ê²°ê³¼ë“¤
    experiment_results = {
        "experiment_info": {
            "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "environment": "ContinuousCartPole-v0",
            "purpose": "DQN vs DDPG ë™ì¼ í™˜ê²½ ê³µì • ë¹„êµ",
            "episodes": 500,
            "evaluation_episodes": 10
        },
        
        "training_performance": {
            "dqn": {
                "final_score": 498.95,
                "training_highlights": [
                    "Episode 100: 207.1ì  ë‹¬ì„±",
                    "Episode 150: 500ì  ë‹¬ì„± (ìµœê³  ì„±ëŠ¥)",
                    "ì¤‘ê°„ì— ì„±ëŠ¥ ì €í•˜ í›„ ë‹¤ì‹œ íšŒë³µ",
                    "ìµœì¢…ì ìœ¼ë¡œ ê±°ì˜ ìµœê³  ì„±ëŠ¥ ìœ ì§€"
                ],
                "learning_stability": "ë¶ˆì•ˆì •í•˜ì§€ë§Œ ë†’ì€ ìµœì¢… ì„±ëŠ¥"
            },
            "ddpg": {
                "final_score": 37.80,
                "training_highlights": [
                    "ì´ˆê¸° 300 ì—í”¼ì†Œë“œ: ë§¤ìš° ë‚®ì€ ì„±ëŠ¥ (9-10ì )",
                    "Episode 350: 88.4ì ìœ¼ë¡œ ê°œì„ ",
                    "Episode 400: 116.1ì  (ìµœê³ ì )",
                    "ì´í›„ ë‹¤ì‹œ ì„±ëŠ¥ ì €í•˜"
                ],
                "learning_stability": "ë§¤ìš° ë¶ˆì•ˆì •í•˜ê³  ë‚®ì€ ìµœì¢… ì„±ëŠ¥"
            }
        },
        
        "deterministic_policy_analysis": {
            "dqn": {
                "determinism_score": 1.0,
                "consistency_rate": 1.0,
                "q_value_stability": 0.0,
                "mechanism": "Q-value argmax (implicit deterministic)",
                "action_range": [-1.0, 0.8]
            },
            "ddpg": {
                "determinism_score": 1.0,
                "consistency_rate": 1.0,
                "output_variance": 0.0,
                "mechanism": "Actor network direct output (explicit deterministic)",
                "action_range": [0.981, 0.996]
            }
        },
        
        "action_comparison": {
            "mean_difference": 1.275,
            "max_difference": 1.996,
            "correlation": -0.031,
            "analysis": "ë‘ ì•Œê³ ë¦¬ì¦˜ì´ ì™„ì „íˆ ë‹¤ë¥¸ í–‰ë™ ì „ëµ ì‚¬ìš©"
        },
        
        "key_findings": [
            "DQNì´ ContinuousCartPole í™˜ê²½ì—ì„œ DDPGë³´ë‹¤ í›¨ì”¬ ìš°ìˆ˜í•œ ì„±ëŠ¥",
            "ë‘ ì•Œê³ ë¦¬ì¦˜ ëª¨ë‘ ì™„ë²½í•œ ê²°ì •ì„± ë‹¬ì„± (determinism_score = 1.0)",
            "DQNì€ ë‹¤ì–‘í•œ í–‰ë™ ë²”ìœ„ ì‚¬ìš©, DDPGëŠ” ì œí•œëœ ë²”ìœ„ì—ì„œë§Œ í–‰ë™",
            "í–‰ë™ ì„ íƒ íŒ¨í„´ì—ì„œ ê±°ì˜ ìƒê´€ê´€ê³„ ì—†ìŒ (correlation = -0.031)",
            "DQNì˜ ì´ì‚°í™” ë°©ì‹ì´ ì´ í™˜ê²½ì—ì„œëŠ” ë” íš¨ê³¼ì "
        ],
        
        "educational_insights": [
            "ë™ì¼ í™˜ê²½ì—ì„œë„ ì•Œê³ ë¦¬ì¦˜ë³„ ì„±ëŠ¥ ì°¨ì´ê°€ ë§¤ìš° í´ ìˆ˜ ìˆìŒ",
            "ì—°ì† ì œì–´ í™˜ê²½ì´ë¼ê³  í•´ì„œ DDPGê°€ í•­ìƒ ìœ ë¦¬í•œ ê²ƒì€ ì•„ë‹˜",
            "DQNì˜ ì´ì‚°í™” ì „ëµì´ íŠ¹ì • ì—°ì† í™˜ê²½ì—ì„œ íš¨ê³¼ì ì¼ ìˆ˜ ìˆìŒ",
            "ê²°ì •ì  ì •ì±… êµ¬í˜„ ë°©ì‹(ì•”ë¬µì  vs ëª…ì‹œì )ë³´ë‹¤ íƒí—˜ ì „ëµì´ ë” ì¤‘ìš”í•  ìˆ˜ ìˆìŒ"
        ]
    }
    
    return experiment_results

def save_experiment_results():
    """ì‹¤í—˜ ê²°ê³¼ ì €ì¥"""
    results = create_experiment_summary()
    
    # ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ë£¨íŠ¸ë¡œ ë³€ê²½
    os.chdir(project_root)
    
    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    save_dir = "results/same_environment_comparison"
    os.makedirs(save_dir, exist_ok=True)
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    json_path = os.path.join(save_dir, f"experiment_summary_{timestamp}.json")
    
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {json_path}")
    return json_path, results

def print_detailed_analysis(results):
    """ìƒì„¸ ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
    print("=" * 80)
    print("ğŸ”¬ ë™ì¼ í™˜ê²½ DQN vs DDPG ì‹¤í—˜ ê²°ê³¼ ìƒì„¸ ë¶„ì„")
    print("=" * 80)
    
    print(f"\nğŸ“… ì‹¤í—˜ ì •ë³´:")
    info = results["experiment_info"]
    print(f"  â€¢ ë‚ ì§œ: {info['date']}")
    print(f"  â€¢ í™˜ê²½: {info['environment']}")
    print(f"  â€¢ ëª©ì : {info['purpose']}")
    print(f"  â€¢ í›ˆë ¨ ì—í”¼ì†Œë“œ: {info['episodes']}")
    
    print(f"\nğŸ† ìµœì¢… ì„±ëŠ¥ ë¹„êµ:")
    dqn_score = results["training_performance"]["dqn"]["final_score"]
    ddpg_score = results["training_performance"]["ddpg"]["final_score"]
    print(f"  â€¢ DQN ìµœì¢… ì ìˆ˜: {dqn_score:.2f}")
    print(f"  â€¢ DDPG ìµœì¢… ì ìˆ˜: {ddpg_score:.2f}")
    print(f"  â€¢ ì„±ëŠ¥ ì°¨ì´: {dqn_score - ddpg_score:.2f} (DQN ìš°ìœ„)")
    print(f"  â€¢ ì„±ëŠ¥ ë¹„ìœ¨: DQNì´ DDPGë³´ë‹¤ {dqn_score/ddpg_score:.1f}ë°° ë†’ìŒ")
    
    print(f"\nğŸ“ˆ í•™ìŠµ ê³¼ì • ë¶„ì„:")
    print("  DQN í•™ìŠµ íŠ¹ì§•:")
    for highlight in results["training_performance"]["dqn"]["training_highlights"]:
        print(f"    - {highlight}")
    
    print("  DDPG í•™ìŠµ íŠ¹ì§•:")  
    for highlight in results["training_performance"]["ddpg"]["training_highlights"]:
        print(f"    - {highlight}")
    
    print(f"\nğŸ¯ ê²°ì •ì  ì •ì±… ë¶„ì„:")
    dqn_det = results["deterministic_policy_analysis"]["dqn"]
    ddpg_det = results["deterministic_policy_analysis"]["ddpg"]
    
    print("  DQN (ì•”ë¬µì  ê²°ì •ì  ì •ì±…):")
    print(f"    - ê²°ì •ì„± ì ìˆ˜: {dqn_det['determinism_score']}")
    print(f"    - ë©”ì»¤ë‹ˆì¦˜: {dqn_det['mechanism']}")
    print(f"    - í–‰ë™ ë²”ìœ„: {dqn_det['action_range']}")
    
    print("  DDPG (ëª…ì‹œì  ê²°ì •ì  ì •ì±…):")
    print(f"    - ê²°ì •ì„± ì ìˆ˜: {ddpg_det['determinism_score']}")
    print(f"    - ë©”ì»¤ë‹ˆì¦˜: {ddpg_det['mechanism']}")
    print(f"    - í–‰ë™ ë²”ìœ„: {ddpg_det['action_range']}")
    
    print(f"\nğŸ” í–‰ë™ ì„ íƒ ë¹„êµ:")
    action_comp = results["action_comparison"]
    print(f"  â€¢ í‰ê·  í–‰ë™ ì°¨ì´: {action_comp['mean_difference']:.3f}")
    print(f"  â€¢ ìµœëŒ€ í–‰ë™ ì°¨ì´: {action_comp['max_difference']:.3f}")
    print(f"  â€¢ í–‰ë™ ìƒê´€ê´€ê³„: {action_comp['correlation']:.3f}")
    print(f"  â€¢ ë¶„ì„: {action_comp['analysis']}")
    
    print(f"\nğŸ’¡ í•µì‹¬ ë°œê²¬ì‚¬í•­:")
    for i, finding in enumerate(results["key_findings"], 1):
        print(f"  {i}. {finding}")
    
    print(f"\nğŸ“ êµìœ¡ì  ì‹œì‚¬ì :")
    for i, insight in enumerate(results["educational_insights"], 1):
        print(f"  {i}. {insight}")
    
    print(f"\n" + "=" * 80)

def create_comparison_report():
    """ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±"""
    report_content = """
# ë™ì¼ í™˜ê²½ DQN vs DDPG ì‹¤í—˜ ë¦¬í¬íŠ¸

## ì‹¤í—˜ ê°œìš”
- **í™˜ê²½**: ContinuousCartPole-v0 (CartPole ë¬¼ë¦¬ + ì—°ì† í–‰ë™ ê³µê°„)
- **ëª©ì **: í™˜ê²½ ì°¨ì´ë¥¼ ë°°ì œí•œ ìˆœìˆ˜ ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ ë¹„êµ
- **ê¸°ê°„**: ê° ì•Œê³ ë¦¬ì¦˜ 500 ì—í”¼ì†Œë“œ í›ˆë ¨

## ì£¼ìš” ê²°ê³¼

### ì„±ëŠ¥ ë¹„êµ
| ì•Œê³ ë¦¬ì¦˜ | ìµœì¢… ì ìˆ˜ | ìµœê³  ì ìˆ˜ | í•™ìŠµ ì•ˆì •ì„± |
|---------|----------|----------|-------------|
| DQN     | 498.95   | 500      | ë¶ˆì•ˆì •í•˜ì§€ë§Œ ë†’ì€ ìµœì¢… ì„±ëŠ¥ |
| DDPG    | 37.80    | 116.1    | ë§¤ìš° ë¶ˆì•ˆì •í•˜ê³  ë‚®ì€ ì„±ëŠ¥ |

### ê²°ì •ì  ì •ì±… íŠ¹ì„±
- **DQN**: Q-value argmax ë°©ì‹ (ì•”ë¬µì ), í–‰ë™ ë²”ìœ„ [-1.0, 0.8]
- **DDPG**: Actor ì§ì ‘ ì¶œë ¥ ë°©ì‹ (ëª…ì‹œì ), í–‰ë™ ë²”ìœ„ [0.98, 1.0]
- **ê³µí†µì **: ë‘ ì•Œê³ ë¦¬ì¦˜ ëª¨ë‘ ì™„ë²½í•œ ê²°ì •ì„± ë‹¬ì„± (ë¶„ì‚° = 0)

### í–‰ë™ ì„ íƒ íŒ¨í„´
- í‰ê·  í–‰ë™ ì°¨ì´: 1.275 (í° ì°¨ì´)
- í–‰ë™ ìƒê´€ê´€ê³„: -0.031 (ê±°ì˜ ë¬´ê´€)
- DQNì€ ë‹¤ì–‘í•œ í–‰ë™, DDPGëŠ” í•œìª½ìœ¼ë¡œ ì¹˜ìš°ì¹œ í–‰ë™

## í•µì‹¬ ì¸ì‚¬ì´íŠ¸

1. **í™˜ê²½ ì í•©ì„±ì´ ì•Œê³ ë¦¬ì¦˜ ìœ í˜•ë³´ë‹¤ ì¤‘ìš”**: ì—°ì† í™˜ê²½ì´ë¼ê³  í•´ì„œ DDPGê°€ ë°˜ë“œì‹œ ìœ ë¦¬í•˜ì§€ ì•ŠìŒ
2. **ì´ì‚°í™” ì „ëµì˜ íš¨ê³¼**: DQNì˜ í–‰ë™ ì´ì‚°í™”ê°€ ì´ í™˜ê²½ì—ì„œëŠ” ë” íš¨ê³¼ì 
3. **íƒí—˜ ì „ëµì˜ ì¤‘ìš”ì„±**: epsilon-greedy vs ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆì˜ ì°¨ì´ê°€ ì„±ëŠ¥ì— í° ì˜í–¥
4. **í•™ìŠµ ì•ˆì •ì„±**: DQNì´ ë” ì•ˆì •ì ì´ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ í•™ìŠµ ê³¡ì„ 

## êµìœ¡ì  ê°€ì¹˜

ì´ ì‹¤í—˜ì€ ë‹¤ìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤:
- ì•Œê³ ë¦¬ì¦˜ ì„ íƒ ì‹œ ì´ë¡ ì  ì í•©ì„±ë¿ë§Œ ì•„ë‹ˆë¼ ì‹¤ì œ ì„±ëŠ¥ë„ ê³ ë ¤í•´ì•¼ í•¨
- ë™ì¼ ì¡°ê±´ì—ì„œì˜ ê³µì •í•œ ë¹„êµì˜ ì¤‘ìš”ì„±
- ê²°ì •ì  ì •ì±…ì˜ ë‹¤ì–‘í•œ êµ¬í˜„ ë°©ì‹ê³¼ ê·¸ íš¨ê³¼

## í–¥í›„ ì—°êµ¬ ë°©í–¥

1. ë‹¤ë¥¸ ì—°ì† ì œì–´ í™˜ê²½ì—ì„œì˜ ë¹„êµ ì‹¤í—˜
2. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ í†µí•œ DDPG ì„±ëŠ¥ ê°œì„ 
3. ì´ì‚°í™” í•´ìƒë„ê°€ DQN ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„
"""
    
    return report_content

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("ë™ì¼ í™˜ê²½ DQN vs DDPG ì‹¤í—˜ ê²°ê³¼ ë¶„ì„")
    
    # ê²°ê³¼ ì €ì¥
    json_path, results = save_experiment_results()
    
    # ìƒì„¸ ë¶„ì„ ì¶œë ¥
    print_detailed_analysis(results)
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    report_content = create_comparison_report()
    report_path = json_path.replace('.json', '_report.md')
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    print(f"\nğŸ“‹ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {report_path}")
    
    print(f"\nğŸ‰ ì‹¤í—˜ ë¶„ì„ ì™„ë£Œ!")
    print(f"  â€¢ JSON ê²°ê³¼: {json_path}")
    print(f"  â€¢ ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸: {report_path}")

if __name__ == "__main__":
    main()