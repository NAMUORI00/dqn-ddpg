"""
í†µí•© ë¹„ë””ì˜¤ ë Œë”ë§ íŒŒì´í”„ë¼ì¸
ì „ì²´ í•™ìŠµ ê³¼ì •ì„ ì‹œê°í™”í•˜ê³  ì˜ìƒìœ¼ë¡œ ìƒì„±í•˜ëŠ” ì‹œìŠ¤í…œ
"""

import os
import json
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from matplotlib.patches import Rectangle
import cv2
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
import yaml
from datetime import datetime
import shutil

try:
    from .video_manager import VideoManager, VideoConfig
except ImportError:
    from video_manager import VideoManager, VideoConfig


@dataclass
class PipelineConfig:
    """íŒŒì´í”„ë¼ì¸ ì„¤ì •"""
    # ê¸°ë³¸ ì„¤ì •
    output_dir: str = "videos/pipeline"
    temp_dir: str = "videos/temp"
    
    # ë¹„ë””ì˜¤ ì„¤ì •
    fps: int = 30
    duration_seconds: int = 180  # 3ë¶„
    resolution: Tuple[int, int] = (1280, 720)
    
    # ì‹œê°í™” ì„¤ì •
    show_metrics: bool = True
    show_progress: bool = True
    show_episode_info: bool = True
    
    # ë°ì´í„° ì„¤ì •
    max_episodes_to_show: int = 1000
    smooth_curves: bool = True
    
    @classmethod
    def from_yaml(cls, config_path: str) -> 'PipelineConfig':
        """YAML íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ"""
        with open(config_path, 'r', encoding='utf-8') as f:
            config_dict = yaml.safe_load(f)
        
        return cls(**config_dict.get('pipeline', {}))


class VideoRenderingPipeline:
    """ì „ì²´ ë¹„ë””ì˜¤ ë Œë”ë§ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, config: PipelineConfig):
        self.config = config
        self.setup_directories()
        
        # ìƒíƒœ ë³€ìˆ˜
        self.current_frame = 0
        self.total_frames = config.fps * config.duration_seconds
        
        # ë°ì´í„° ì €ì¥
        self.dqn_data = None
        self.ddpg_data = None
        
        # ì‹œê°í™” ì„¤ì •
        plt.style.use('dark_background')
        self.colors = {
            'dqn': '#00ff88',
            'ddpg': '#ff6b6b',
            'background': '#1a1a1a',
            'text': '#ffffff',
            'grid': '#333333'
        }
    
    def setup_directories(self):
        """ë””ë ‰í† ë¦¬ ì„¤ì •"""
        self.output_path = Path(self.config.output_dir)
        self.temp_path = Path(self.config.temp_dir)
        
        self.output_path.mkdir(parents=True, exist_ok=True)
        self.temp_path.mkdir(parents=True, exist_ok=True)
    
    def load_training_data(self, dqn_results_path: str, ddpg_results_path: str):
        """í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
        try:
            with open(dqn_results_path, 'r') as f:
                self.dqn_data = json.load(f)
            print(f"[INFO] DQN ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.dqn_data.get('metrics', {}).get('episode_rewards', []))} ì—í”¼ì†Œë“œ")
        except Exception as e:
            print(f"[WARNING] DQN ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.dqn_data = self._create_dummy_data('dqn')
        
        try:
            with open(ddpg_results_path, 'r') as f:
                self.ddpg_data = json.load(f)
            print(f"[INFO] DDPG ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.ddpg_data.get('metrics', {}).get('episode_rewards', []))} ì—í”¼ì†Œë“œ")
        except Exception as e:
            print(f"[WARNING] DDPG ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.ddpg_data = self._create_dummy_data('ddpg')
    
    def _create_dummy_data(self, algorithm: str) -> Dict:
        """ë”ë¯¸ ë°ì´í„° ìƒì„± (ë°ì´í„°ê°€ ì—†ì„ ë•Œ ì‚¬ìš©)"""
        np.random.seed(42)
        
        if algorithm == 'dqn':
            episodes = 500
            rewards = []
            for i in range(episodes):
                # í•™ìŠµ ê³¡ì„  ì‹œë®¬ë ˆì´ì…˜
                base_reward = min(400, 50 + i * 0.7)
                noise = np.random.normal(0, 20)
                reward = max(0, base_reward + noise)
                rewards.append(reward)
        else:  # ddpg
            episodes = 400
            rewards = []
            for i in range(episodes):
                # DDPG í•™ìŠµ ê³¡ì„  ì‹œë®¬ë ˆì´ì…˜
                base_reward = max(-1000, -800 + i * 1.5)
                noise = np.random.normal(0, 50)
                reward = min(0, base_reward + noise)
                rewards.append(reward)
        
        return {
            'metrics': {
                'episode_rewards': rewards,
                'episode_lengths': [np.random.randint(50, 200) for _ in range(episodes)],
                'training_losses': [np.random.exponential(0.1) for _ in range(episodes * 10)],
                'q_values': [np.random.normal(0, 1) for _ in range(episodes * 10)]
            },
            'config': {
                'algorithm': algorithm.upper(),
                'environment': 'CartPole-v1' if algorithm == 'dqn' else 'Pendulum-v1'
            }
        }
    
    def create_learning_animation(self, output_filename: str = "learning_process.mp4"):
        """í•™ìŠµ ê³¼ì • ì• ë‹ˆë©”ì´ì…˜ ìƒì„±"""
        print("[INFO] í•™ìŠµ ê³¼ì • ì• ë‹ˆë©”ì´ì…˜ ìƒì„± ì‹œì‘...")
        
        # í”¼ê·¸ ì„¤ì •
        fig = plt.figure(figsize=(16, 9), facecolor=self.colors['background'])
        fig.suptitle('DQN vs DDPG í•™ìŠµ ê³¼ì • ì‹œê°í™”', 
                    fontsize=20, color=self.colors['text'], y=0.95)
        
        # ì„œë¸Œí”Œë¡¯ ìƒì„±
        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
        
        # ë©”ì¸ í•™ìŠµ ê³¡ì„ 
        ax_main = fig.add_subplot(gs[0, :])
        ax_main.set_facecolor(self.colors['background'])
        
        # ë³´ì¡° í”Œë¡¯ë“¤
        ax_lengths = fig.add_subplot(gs[1, 0])
        ax_losses = fig.add_subplot(gs[1, 1])
        ax_q_values = fig.add_subplot(gs[1, 2])
        
        # í†µê³„ í‘œì‹œ
        ax_stats = fig.add_subplot(gs[2, :])
        ax_stats.axis('off')
        
        # ëª¨ë“  ì¶• ì„¤ì •
        for ax in [ax_main, ax_lengths, ax_losses, ax_q_values]:
            ax.set_facecolor(self.colors['background'])
            ax.tick_params(colors=self.colors['text'])
            ax.grid(True, color=self.colors['grid'], alpha=0.3)
        
        # ë°ì´í„° ì¤€ë¹„
        dqn_rewards = self.dqn_data['metrics']['episode_rewards']
        ddpg_rewards = self.ddpg_data['metrics']['episode_rewards']
        
        max_episodes = max(len(dqn_rewards), len(ddpg_rewards))
        
        def animate(frame):
            # í˜„ì¬ í”„ë ˆì„ì—ì„œ ë³´ì—¬ì¤„ ì—í”¼ì†Œë“œ ìˆ˜ ê³„ì‚°
            current_episode = int((frame / self.total_frames) * max_episodes)
            
            # ëª¨ë“  í”Œë¡¯ í´ë¦¬ì–´
            ax_main.clear()
            ax_lengths.clear()
            ax_losses.clear()
            ax_q_values.clear()
            
            # ì¶• ì„¤ì • ì¬ì ìš©
            for ax in [ax_main, ax_lengths, ax_losses, ax_q_values]:
                ax.set_facecolor(self.colors['background'])
                ax.tick_params(colors=self.colors['text'])
                ax.grid(True, color=self.colors['grid'], alpha=0.3)
            
            # 1. ë©”ì¸ í•™ìŠµ ê³¡ì„ 
            if current_episode > 0:
                dqn_end = min(current_episode, len(dqn_rewards))
                ddpg_end = min(current_episode, len(ddpg_rewards))
                
                if dqn_end > 0:
                    episodes_dqn = range(dqn_end)
                    ax_main.plot(episodes_dqn, dqn_rewards[:dqn_end], 
                               color=self.colors['dqn'], label='DQN', linewidth=2)
                    
                    # ì´ë™í‰ê· 
                    if dqn_end > 20:
                        window = min(50, dqn_end // 5)
                        ma_rewards = np.convolve(dqn_rewards[:dqn_end], 
                                               np.ones(window)/window, mode='valid')
                        ax_main.plot(range(window-1, dqn_end), ma_rewards, 
                                   color=self.colors['dqn'], linewidth=3, alpha=0.8)
                
                if ddpg_end > 0:
                    episodes_ddpg = range(ddpg_end)
                    ax_main.plot(episodes_ddpg, ddpg_rewards[:ddpg_end], 
                               color=self.colors['ddpg'], label='DDPG', linewidth=2)
                    
                    # ì´ë™í‰ê· 
                    if ddpg_end > 20:
                        window = min(50, ddpg_end // 5)
                        ma_rewards = np.convolve(ddpg_rewards[:ddpg_end], 
                                               np.ones(window)/window, mode='valid')
                        ax_main.plot(range(window-1, ddpg_end), ma_rewards, 
                                   color=self.colors['ddpg'], linewidth=3, alpha=0.8)
            
            ax_main.set_xlabel('Episode', color=self.colors['text'])
            ax_main.set_ylabel('Reward', color=self.colors['text'])
            ax_main.set_title('í•™ìŠµ ê³¡ì„ ', color=self.colors['text'])
            ax_main.legend(facecolor=self.colors['background'], 
                         edgecolor=self.colors['text'], labelcolor=self.colors['text'])
            
            # 2. ì—í”¼ì†Œë“œ ê¸¸ì´
            if current_episode > 0:
                dqn_lengths = self.dqn_data['metrics']['episode_lengths'][:min(current_episode, len(dqn_rewards))]
                ddpg_lengths = self.ddpg_data['metrics']['episode_lengths'][:min(current_episode, len(ddpg_rewards))]
                
                if dqn_lengths:
                    ax_lengths.plot(dqn_lengths, color=self.colors['dqn'], alpha=0.7)
                if ddpg_lengths:
                    ax_lengths.plot(ddpg_lengths, color=self.colors['ddpg'], alpha=0.7)
            
            ax_lengths.set_xlabel('Episode', color=self.colors['text'])
            ax_lengths.set_ylabel('Length', color=self.colors['text'])
            ax_lengths.set_title('ì—í”¼ì†Œë“œ ê¸¸ì´', color=self.colors['text'])
            
            # 3. í•™ìŠµ ì†ì‹¤
            if current_episode > 0:
                loss_steps = min(current_episode * 10, len(self.dqn_data['metrics']['training_losses']))
                if loss_steps > 0:
                    ax_losses.plot(self.dqn_data['metrics']['training_losses'][:loss_steps], 
                                 color=self.colors['dqn'], alpha=0.7)
                    ax_losses.plot(self.ddpg_data['metrics']['training_losses'][:loss_steps], 
                                 color=self.colors['ddpg'], alpha=0.7)
            
            ax_losses.set_xlabel('Training Step', color=self.colors['text'])
            ax_losses.set_ylabel('Loss', color=self.colors['text'])
            ax_losses.set_title('í•™ìŠµ ì†ì‹¤', color=self.colors['text'])
            ax_losses.set_yscale('log')
            
            # 4. Q-ê°’ ë³€í™”
            if current_episode > 0:
                q_steps = min(current_episode * 10, len(self.dqn_data['metrics']['q_values']))
                if q_steps > 0:
                    ax_q_values.plot(self.dqn_data['metrics']['q_values'][:q_steps], 
                                   color=self.colors['dqn'], alpha=0.7)
                    ax_q_values.plot(self.ddpg_data['metrics']['q_values'][:q_steps], 
                                   color=self.colors['ddpg'], alpha=0.7)
            
            ax_q_values.set_xlabel('Training Step', color=self.colors['text'])
            ax_q_values.set_ylabel('Q-value', color=self.colors['text'])
            ax_q_values.set_title('Q-ê°’ ë³€í™”', color=self.colors['text'])
            
            # 5. í˜„ì¬ í†µê³„
            progress = (frame / self.total_frames) * 100
            stats_text = f"""
            ì§„í–‰ë¥ : {progress:.1f}% | í˜„ì¬ ì—í”¼ì†Œë“œ: {current_episode}/{max_episodes}
            
            DQN (CartPole): í‰ê·  ë³´ìƒ {np.mean(dqn_rewards[:current_episode]) if current_episode > 0 else 0:.1f}
            DDPG (Pendulum): í‰ê·  ë³´ìƒ {np.mean(ddpg_rewards[:current_episode]) if current_episode > 0 else 0:.1f}
            """
            
            ax_stats.text(0.5, 0.5, stats_text, 
                         transform=ax_stats.transAxes,
                         ha='center', va='center',
                         color=self.colors['text'],
                         fontsize=14,
                         bbox=dict(boxstyle="round,pad=0.3", 
                                 facecolor=self.colors['background'],
                                 edgecolor=self.colors['text']))
        
        # ì• ë‹ˆë©”ì´ì…˜ ìƒì„±
        anim = animation.FuncAnimation(fig, animate, frames=self.total_frames, 
                                     interval=1000//self.config.fps, blit=False)
        
        # ì €ì¥
        output_path = self.output_path / output_filename
        print(f"[INFO] ì• ë‹ˆë©”ì´ì…˜ ì €ì¥ ì¤‘: {output_path}")
        
        # ffmpeg ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ì— ë”°ë¼ writer ì„ íƒ
        import subprocess
        try:
            subprocess.run(['ffmpeg', '-version'], 
                          capture_output=True, check=True, timeout=5)
            writer = animation.FFMpegWriter(fps=self.config.fps, bitrate=5000)
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
            print("[WARNING] ffmpegì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
            # ê°œë³„ í”„ë ˆì„ì„ ì´ë¯¸ì§€ë¡œ ì €ì¥í•˜ê³  OpenCVë¡œ ë¹„ë””ì˜¤ ìƒì„±
            return self._save_animation_with_opencv(fig, animate, output_path)
        
        try:
            anim.save(str(output_path), writer=writer, dpi=100)
            plt.close(fig)
            print(f"[INFO] ì• ë‹ˆë©”ì´ì…˜ ì €ì¥ ì™„ë£Œ: {output_path}")
            return str(output_path)
        except Exception as e:
            print(f"[ERROR] FFmpeg ì €ì¥ ì‹¤íŒ¨: {e}")
            plt.close(fig)
            # OpenCV ë°±ì—… ë°©ë²•
            return self._save_animation_with_opencv(fig, animate, output_path)
    
    def _save_animation_with_opencv(self, fig, animate_func, output_path: Path) -> str:
        """OpenCVë¥¼ ì‚¬ìš©í•œ ì• ë‹ˆë©”ì´ì…˜ ì €ì¥ (ffmpeg ëŒ€ì•ˆ)"""
        print("[INFO] OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ ìƒì„± ì¤‘...")
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬ì— í”„ë ˆì„ ì €ì¥
        frames_dir = self.temp_path / "frames"
        frames_dir.mkdir(exist_ok=True)
        
        # ê° í”„ë ˆì„ì„ ì´ë¯¸ì§€ë¡œ ì €ì¥
        frame_paths = []
        for frame_idx in range(min(self.total_frames, 300)):  # ìµœëŒ€ 300í”„ë ˆì„ìœ¼ë¡œ ì œí•œ
            animate_func(frame_idx)
            frame_path = frames_dir / f"frame_{frame_idx:04d}.png"
            fig.savefig(frame_path, dpi=80, facecolor=self.colors['background'])
            frame_paths.append(str(frame_path))
            
            if frame_idx % 50 == 0:
                print(f"[INFO] í”„ë ˆì„ ì§„í–‰ë¥ : {frame_idx}/{min(self.total_frames, 300)}")
        
        plt.close(fig)
        
        # OpenCVë¡œ ë¹„ë””ì˜¤ ìƒì„±
        if frame_paths:
            first_frame = cv2.imread(frame_paths[0])
            height, width, _ = first_frame.shape
            
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(str(output_path), fourcc, self.config.fps, (width, height))
            
            for frame_path in frame_paths:
                frame = cv2.imread(frame_path)
                if frame is not None:
                    out.write(frame)
            
            out.release()
            
            # ì„ì‹œ í”„ë ˆì„ ì‚­ì œ
            for frame_path in frame_paths:
                os.remove(frame_path)
            frames_dir.rmdir()
            
            print(f"[INFO] OpenCV ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
            return str(output_path)
        else:
            print("[ERROR] í”„ë ˆì„ ìƒì„± ì‹¤íŒ¨")
            return None
    
    def create_comparison_video(self, output_filename: str = "algorithm_comparison.mp4"):
        """ì•Œê³ ë¦¬ì¦˜ ë¹„êµ ë¹„ë””ì˜¤ ìƒì„±"""
        print("[INFO] ì•Œê³ ë¦¬ì¦˜ ë¹„êµ ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘...")
        
        # ë¹„êµ ë°ì´í„° ì¤€ë¹„
        dqn_final_performance = {
            'mean_reward': np.mean(self.dqn_data['metrics']['episode_rewards'][-100:]),
            'std_reward': np.std(self.dqn_data['metrics']['episode_rewards'][-100:]),
            'mean_length': np.mean(self.dqn_data['metrics']['episode_lengths'][-100:]),
            'convergence_episode': self._find_convergence_episode(self.dqn_data['metrics']['episode_rewards'])
        }
        
        ddpg_final_performance = {
            'mean_reward': np.mean(self.ddpg_data['metrics']['episode_rewards'][-100:]),
            'std_reward': np.std(self.ddpg_data['metrics']['episode_rewards'][-100:]),
            'mean_length': np.mean(self.ddpg_data['metrics']['episode_lengths'][-100:]),
            'convergence_episode': self._find_convergence_episode(self.ddpg_data['metrics']['episode_rewards'])
        }
        
        # ì •ì  ë¹„êµ ì´ë¯¸ì§€ ìƒì„±
        fig, axes = plt.subplots(2, 2, figsize=(16, 12), facecolor=self.colors['background'])
        fig.suptitle('DQN vs DDPG ìµœì¢… ì„±ëŠ¥ ë¹„êµ', fontsize=20, color=self.colors['text'])
        
        # 1. ìµœì¢… ì„±ëŠ¥ ë°” ì°¨íŠ¸
        ax = axes[0, 0]
        ax.set_facecolor(self.colors['background'])
        algorithms = ['DQN', 'DDPG']
        rewards = [dqn_final_performance['mean_reward'], ddpg_final_performance['mean_reward']]
        errors = [dqn_final_performance['std_reward'], ddpg_final_performance['std_reward']]
        
        bars = ax.bar(algorithms, rewards, yerr=errors, 
                     color=[self.colors['dqn'], self.colors['ddpg']], alpha=0.8)
        ax.set_ylabel('Average Reward', color=self.colors['text'])
        ax.set_title('ìµœì¢… í‰ê·  ë³´ìƒ', color=self.colors['text'])
        ax.tick_params(colors=self.colors['text'])
        ax.grid(True, color=self.colors['grid'], alpha=0.3)
        
        # 2. í•™ìŠµ ê³¡ì„  ì „ì²´
        ax = axes[0, 1]
        ax.set_facecolor(self.colors['background'])
        ax.plot(self.dqn_data['metrics']['episode_rewards'], 
               color=self.colors['dqn'], label='DQN', alpha=0.7)
        ax.plot(self.ddpg_data['metrics']['episode_rewards'], 
               color=self.colors['ddpg'], label='DDPG', alpha=0.7)
        ax.set_xlabel('Episode', color=self.colors['text'])
        ax.set_ylabel('Reward', color=self.colors['text'])
        ax.set_title('ì „ì²´ í•™ìŠµ ê³¡ì„ ', color=self.colors['text'])
        ax.legend(facecolor=self.colors['background'], labelcolor=self.colors['text'])
        ax.tick_params(colors=self.colors['text'])
        ax.grid(True, color=self.colors['grid'], alpha=0.3)
        
        # 3. ìˆ˜ë ´ ì†ë„ ë¹„êµ
        ax = axes[1, 0]
        ax.set_facecolor(self.colors['background'])
        convergence_data = [dqn_final_performance['convergence_episode'], 
                          ddpg_final_performance['convergence_episode']]
        bars = ax.bar(algorithms, convergence_data, 
                     color=[self.colors['dqn'], self.colors['ddpg']], alpha=0.8)
        ax.set_ylabel('Episode', color=self.colors['text'])
        ax.set_title('ìˆ˜ë ´ ì†ë„ (ì—í”¼ì†Œë“œ)', color=self.colors['text'])
        ax.tick_params(colors=self.colors['text'])
        ax.grid(True, color=self.colors['grid'], alpha=0.3)
        
        # 4. í•™ìŠµ ì•ˆì •ì„±
        ax = axes[1, 1]
        ax.set_facecolor(self.colors['background'])
        
        # ìµœê·¼ 100 ì—í”¼ì†Œë“œì˜ ë¶„ì‚° ê³„ì‚°
        dqn_recent_var = np.var(self.dqn_data['metrics']['episode_rewards'][-100:])
        ddpg_recent_var = np.var(self.ddpg_data['metrics']['episode_rewards'][-100:])
        
        variances = [dqn_recent_var, ddpg_recent_var]
        bars = ax.bar(algorithms, variances, 
                     color=[self.colors['dqn'], self.colors['ddpg']], alpha=0.8)
        ax.set_ylabel('Variance', color=self.colors['text'])
        ax.set_title('í•™ìŠµ ì•ˆì •ì„± (ë‚®ì„ìˆ˜ë¡ ì•ˆì •)', color=self.colors['text'])
        ax.tick_params(colors=self.colors['text'])
        ax.grid(True, color=self.colors['grid'], alpha=0.3)
        
        plt.tight_layout()
        
        # ì´ë¯¸ì§€ë¡œ ì €ì¥
        comparison_image_path = self.temp_path / "comparison.png"
        plt.savefig(comparison_image_path, dpi=150, facecolor=self.colors['background'])
        plt.close()
        
        # ì´ë¯¸ì§€ë¥¼ ë¹„ë””ì˜¤ë¡œ ë³€í™˜ (5ì´ˆê°„ í‘œì‹œ)
        output_path = self.output_path / output_filename
        self._image_to_video(str(comparison_image_path), str(output_path), duration=5)
        
        print(f"[INFO] ë¹„êµ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
        return str(output_path)
    
    def _find_convergence_episode(self, rewards: List[float], window: int = 50) -> int:
        """ìˆ˜ë ´ ì§€ì  ì°¾ê¸°"""
        if len(rewards) < window * 2:
            return len(rewards)
        
        # ì´ë™í‰ê· ìœ¼ë¡œ ìˆ˜ë ´ ì§€ì  ì°¾ê¸°
        moving_avg = np.convolve(rewards, np.ones(window)/window, mode='valid')
        
        # ê¸°ìš¸ê¸°ê°€ ì‘ì•„ì§€ëŠ” ì§€ì  ì°¾ê¸°
        gradients = np.gradient(moving_avg)
        
        # ê¸°ìš¸ê¸°ê°€ ì„ê³„ê°’ ì´í•˜ê°€ ë˜ëŠ” ì²« ë²ˆì§¸ ì§€ì 
        threshold = np.std(gradients) * 0.1
        convergence_indices = np.where(np.abs(gradients) < threshold)[0]
        
        return convergence_indices[0] + window if len(convergence_indices) > 0 else len(rewards)
    
    def _image_to_video(self, image_path: str, output_path: str, duration: int = 5):
        """ì´ë¯¸ì§€ë¥¼ ë¹„ë””ì˜¤ë¡œ ë³€í™˜"""
        # OpenCVë¡œ ì´ë¯¸ì§€ ë¡œë“œ
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        
        height, width, _ = img.shape
        
        # ë¹„ë””ì˜¤ ë¼ì´í„° ì„¤ì •
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, self.config.fps, (width, height))
        
        # ì§€ì •ëœ ì‹œê°„ë™ì•ˆ ê°™ì€ í”„ë ˆì„ ë°˜ë³µ
        total_frames = self.config.fps * duration
        for _ in range(total_frames):
            out.write(img)
        
        out.release()
    
    def create_summary_video(self, output_filename: str = "experiment_summary.mp4"):
        """ì‹¤í—˜ ìš”ì•½ ë¹„ë””ì˜¤ ìƒì„±"""
        print("[INFO] ì‹¤í—˜ ìš”ì•½ ë¹„ë””ì˜¤ ìƒì„± ì‹œì‘...")
        
        # ì—¬ëŸ¬ êµ¬ì„± ìš”ì†Œ ë¹„ë””ì˜¤ ìƒì„±
        learning_video = self.create_learning_animation("learning_temp.mp4")
        comparison_video = self.create_comparison_video("comparison_temp.mp4")
        
        # ì¸íŠ¸ë¡œ ìƒì„±
        intro_video = self._create_intro_video()
        
        # ì•„ì›ƒíŠ¸ë¡œ ìƒì„±
        outro_video = self._create_outro_video()
        
        # ëª¨ë“  ë¹„ë””ì˜¤ í•©ì¹˜ê¸°
        output_path = self.output_path / output_filename
        self._concatenate_videos([intro_video, learning_video, comparison_video, outro_video], 
                                str(output_path))
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        self._cleanup_temp_files()
        
        print(f"[INFO] ìš”ì•½ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {output_path}")
        return str(output_path)
    
    def _create_intro_video(self) -> str:
        """ì¸íŠ¸ë¡œ ë¹„ë””ì˜¤ ìƒì„±"""
        fig, ax = plt.subplots(figsize=(16, 9), facecolor=self.colors['background'])
        ax.set_facecolor(self.colors['background'])
        ax.axis('off')
        
        intro_text = """
        DQN vs DDPG
        ê°•í™”í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ ì‹¤í—˜
        
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        
        Deep Q-Network (DQN)
        âš¡ ì´ì‚° í–‰ë™ ê³µê°„ (CartPole-v1)
        âš¡ ì•”ë¬µì  ê²°ì •ì  ì •ì±… (argmax)
        âš¡ Îµ-greedy íƒí—˜ ì „ëµ
        
        Deep Deterministic Policy Gradient (DDPG)  
        âš¡ ì—°ì† í–‰ë™ ê³µê°„ (Pendulum-v1)
        âš¡ ëª…ì‹œì  ê²°ì •ì  ì •ì±… (Actor Network)
        âš¡ ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ íƒí—˜ ì „ëµ
        """
        
        ax.text(0.5, 0.5, intro_text, transform=ax.transAxes, 
               ha='center', va='center', color=self.colors['text'], 
               fontsize=16, weight='bold')
        
        intro_path = self.temp_path / "intro.png"
        plt.savefig(intro_path, dpi=150, facecolor=self.colors['background'])
        plt.close()
        
        intro_video_path = self.temp_path / "intro.mp4"
        self._image_to_video(str(intro_path), str(intro_video_path), duration=3)
        
        return str(intro_video_path)
    
    def _create_outro_video(self) -> str:
        """ì•„ì›ƒíŠ¸ë¡œ ë¹„ë””ì˜¤ ìƒì„±"""
        fig, ax = plt.subplots(figsize=(16, 9), facecolor=self.colors['background'])
        ax.set_facecolor(self.colors['background'])
        ax.axis('off')
        
        # ìµœì¢… ê²°ê³¼ ìš”ì•½
        dqn_final = np.mean(self.dqn_data['metrics']['episode_rewards'][-100:])
        ddpg_final = np.mean(self.ddpg_data['metrics']['episode_rewards'][-100:])
        
        outro_text = f"""
        ì‹¤í—˜ ê²°ê³¼ ìš”ì•½
        
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        
        DQN (CartPole-v1)
        ğŸ“Š ìµœì¢… í‰ê·  ë³´ìƒ: {dqn_final:.1f}
        ğŸ“Š ëª©í‘œ ë‹¬ì„±: {'âœ… ì„±ê³µ' if dqn_final >= 400 else 'âŒ ë¯¸ë‹¬'}
        
        DDPG (Pendulum-v1)
        ğŸ“Š ìµœì¢… í‰ê·  ë³´ìƒ: {ddpg_final:.1f}
        ğŸ“Š ëª©í‘œ ë‹¬ì„±: {'âœ… ì„±ê³µ' if ddpg_final >= -300 else 'âŒ ë¯¸ë‹¬'}
        
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        
        ë‘ ì•Œê³ ë¦¬ì¦˜ ëª¨ë‘ ê°ìì˜ ë„ë©”ì¸ì—ì„œ
        ê²°ì •ì  ì •ì±…ì„ ì„±ê³µì ìœ¼ë¡œ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.
        
        {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
        """
        
        ax.text(0.5, 0.5, outro_text, transform=ax.transAxes, 
               ha='center', va='center', color=self.colors['text'], 
               fontsize=14, weight='bold')
        
        outro_path = self.temp_path / "outro.png"
        plt.savefig(outro_path, dpi=150, facecolor=self.colors['background'])
        plt.close()
        
        outro_video_path = self.temp_path / "outro.mp4"
        self._image_to_video(str(outro_path), str(outro_video_path), duration=3)
        
        return str(outro_video_path)
    
    def _concatenate_videos(self, video_paths: List[str], output_path: str):
        """ë¹„ë””ì˜¤ íŒŒì¼ë“¤ì„ ì—°ê²°"""
        # ffmpegì´ ì—†ëŠ” ê²½ìš° ì²« ë²ˆì§¸ ë¹„ë””ì˜¤ë§Œ ë³µì‚¬
        import subprocess
        import shutil
        
        # ffmpeg ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        try:
            subprocess.run(['ffmpeg', '-version'], 
                          capture_output=True, check=True, timeout=5)
            ffmpeg_available = True
        except (subprocess.CalledProcessError, FileNotFoundError, subprocess.TimeoutExpired):
            ffmpeg_available = False
        
        if not ffmpeg_available:
            print("[WARNING] ffmpegì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ ë¹„ë””ì˜¤ë§Œ ë³µì‚¬í•©ë‹ˆë‹¤.")
            if video_paths:
                shutil.copy2(video_paths[0], output_path)
                print(f"[INFO] ë¹„ë””ì˜¤ ë³µì‚¬ ì™„ë£Œ: {output_path}")
            return
        
        # ì„ì‹œ íŒŒì¼ ëª©ë¡ ìƒì„±
        filelist_path = self.temp_path / "filelist.txt"
        with open(filelist_path, 'w') as f:
            for video_path in video_paths:
                f.write(f"file '{video_path}'\n")
        
        # ffmpeg ëª…ë ¹ ì‹¤í–‰
        cmd = [
            'ffmpeg', '-y', '-f', 'concat', '-safe', '0',
            '-i', str(filelist_path),
            '-c', 'copy',
            str(output_path)
        ]
        
        try:
            subprocess.run(cmd, check=True, capture_output=True)
            print(f"[INFO] ë¹„ë””ì˜¤ ì—°ê²° ì™„ë£Œ: {output_path}")
        except subprocess.CalledProcessError as e:
            print(f"[ERROR] ë¹„ë””ì˜¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            # ëŒ€ì•ˆ: ì²« ë²ˆì§¸ ë¹„ë””ì˜¤ë§Œ ë³µì‚¬
            if video_paths:
                shutil.copy2(video_paths[0], output_path)
                print(f"[INFO] ì²« ë²ˆì§¸ ë¹„ë””ì˜¤ë¥¼ ì¶œë ¥ìœ¼ë¡œ ë³µì‚¬: {output_path}")
    
    def _cleanup_temp_files(self):
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        try:
            for file_path in self.temp_path.glob("*"):
                if file_path.is_file():
                    file_path.unlink()
            print("[INFO] ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
        except Exception as e:
            print(f"[WARNING] ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def run_full_pipeline(self, dqn_results_path: str, ddpg_results_path: str) -> str:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("[INFO] ì „ì²´ ë¹„ë””ì˜¤ ë Œë”ë§ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        # 1. ë°ì´í„° ë¡œë“œ
        self.load_training_data(dqn_results_path, ddpg_results_path)
        
        # 2. ìš”ì•½ ë¹„ë””ì˜¤ ìƒì„±
        summary_video = self.create_summary_video("final_experiment_summary.mp4")
        
        # 3. ê°œë³„ ë¹„ë””ì˜¤ë“¤ë„ ìƒì„±
        learning_video = self.create_learning_animation("detailed_learning_process.mp4")
        comparison_video = self.create_comparison_video("algorithm_comparison.mp4")
        
        print("[INFO] ì „ì²´ ë¹„ë””ì˜¤ ë Œë”ë§ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ")
        print(f"[INFO] ë©”ì¸ ë¹„ë””ì˜¤: {summary_video}")
        print(f"[INFO] í•™ìŠµ ê³¼ì • ë¹„ë””ì˜¤: {learning_video}")
        print(f"[INFO] ë¹„êµ ë¹„ë””ì˜¤: {comparison_video}")
        
        return summary_video


def create_pipeline_from_config(config_path: str = None) -> VideoRenderingPipeline:
    """ì„¤ì •ì—ì„œ íŒŒì´í”„ë¼ì¸ ìƒì„±"""
    if config_path and os.path.exists(config_path):
        config = PipelineConfig.from_yaml(config_path)
    else:
        config = PipelineConfig()
    
    return VideoRenderingPipeline(config)